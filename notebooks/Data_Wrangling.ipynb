{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c1111f",
   "metadata": {},
   "source": [
    "# Suicide Detection - Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae227886",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [Step 1. Imports](#Step-1:--Imports) \n",
    "* [Step 2. Load the Data](#Step-2:--Load-the-Data)\n",
    "* [Step 3.  Review Summary Data](#Step-3:--Look-at-Summary-of-Data)\n",
    "* [Step 4.  Further Data Review (Head)](#Step-4:--Call-head-of-Data)\n",
    "* [Step 5.  Identify Duplicates and Missing Data](#Step-5:--Identify-duplicates-and-missing-data)\n",
    "* [Step 6.  Text Normalization](#Step-6:--Text-Normalization)\n",
    "    * [Step 6a)  Convert Text to Lowercase](#Step-6a:--Convert-all-letters-to-lowercase.)\n",
    "    * [Step 6b)  Convert urls and links to standardized text](#Step-6b:--Convert-urls-and-links-to-standardized-text)\n",
    "    * [Step 6c)  Convert emojis and emoticons to text](#Step-6c:-Convert-emojis-and-emoticons-to-text)\n",
    "    * [Step 6d)  Remove punctuation and numerals](#Step-6d:-Remove-punctuation-and-numerals)\n",
    "    * [Step 6e)  Remove White Spaces](#Step-6e:-Remove-White-Spaces)\n",
    "    * [Step 6f)  Language Detection](#Step-6f:-Language-Detection)\n",
    "    * [Step 6g)  Convert Text to Lowercase](#Step-6g:--Expand-Contractions)\n",
    "    * [Step 6h)  Spell Check](#Step-6h:--Spell-Check)\n",
    "    * [Step 6i)  Filler Words](#Step:-6i:--Filler-Words)\n",
    "    * [Step 6j)  Stop Words and Tokenization](#Step-6j:-Stop-Words-and-Tokenization)\n",
    "    * [Step 6k)  Lemmatization](#Step-6k:-Lemmatization)\n",
    "* [Step 7.  Save Cleaned File](#Step-7:--Save-Cleaned-File)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901d8cc",
   "metadata": {},
   "source": [
    "# Step 1:  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c298676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from six.moves import range\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "import textstat\n",
    "import re\n",
    "import string\n",
    "# !pip install watermark\n",
    "#%load_ext watermark\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124feb1",
   "metadata": {},
   "source": [
    "# Step 2:  Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc4a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Suicide_Detection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b748d03",
   "metadata": {},
   "source": [
    "# Step 3:  Look at Summary of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7100dfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232074 entries, 0 to 232073\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  232074 non-null  int64 \n",
      " 1   text        232074 non-null  object\n",
      " 2   class       232074 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977786f",
   "metadata": {},
   "source": [
    "# Step 4:  Call head of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099b0676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>I’m so lostHello, my name is Adam (16) and I’v...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0           2  Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
       "1           3  Am I weird I don't get affected by compliments...  non-suicide\n",
       "2           4  Finally 2020 is almost over... So I can never ...  non-suicide\n",
       "3           8          i need helpjust help me im crying so hard      suicide\n",
       "4           9  I’m so lostHello, my name is Adam (16) and I’v...      suicide"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655a2f9",
   "metadata": {},
   "source": [
    "# Step 5:  Identify duplicates and missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a2f97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232074"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab24146",
   "metadata": {},
   "source": [
    "This basically tells us that each entry  in the 'text' column is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8a54c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    232074\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c2a647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    232074\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99e282",
   "metadata": {},
   "source": [
    "Great we do not appear to have any duplicates or missing data.  In this regard the data is very clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998e142",
   "metadata": {},
   "source": [
    "# Step 6:  Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2253493",
   "metadata": {},
   "source": [
    "#### Step 6a:  Convert all letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b0a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb68b4d",
   "metadata": {},
   "source": [
    "#### Step 6b:  Convert urls and links to standardized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4bf4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_url(text):\n",
    "    return re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '_link_to_site_', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22844fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  used code snippets from - https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['text'].iloc[i] = standardize_url(df['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b602baf2",
   "metadata": {},
   "source": [
    "#### Step 6c: Convert emojis and emoticons to text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed02e7f",
   "metadata": {},
   "source": [
    "First we will convert emojis to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c594df67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ex wife threatening suiciderecently i left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>am i weird i don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>finally 2020 is almost over... so i can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>i’m so losthello, my name is adam (16) and i’v...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0           2  ex wife threatening suiciderecently i left my ...      suicide\n",
       "1           3  am i weird i don't get affected by compliments...  non-suicide\n",
       "2           4  finally 2020 is almost over... so i can never ...  non-suicide\n",
       "3           8          i need helpjust help me im crying so hard      suicide\n",
       "4           9  i’m so losthello, my name is adam (16) and i’v...      suicide"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b951736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "def5e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_emoji(text):\n",
    "    return emoji.demojize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ffcbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df['text'].iloc[i] = no_emoji(df['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd71546",
   "metadata": {},
   "source": [
    "Next we will convert emoticons to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6243f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emot.emo_unicode import UNICODE_EMOJI # For emojis\n",
    "from emot.emo_unicode import EMOTICONS_EMO# For EMOTICONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f532ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS_EMO:\n",
    "        text = text.replace(emot, EMOTICONS_EMO[emot].replace(\" \",\"_\"))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b328fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Happy_face_smiley Happy_face_smiley'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello :-) :-)\"\n",
    "convert_emoticons(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66d5e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in range(len(df)):\n",
    "    df['text'].iloc[item] = convert_emoticons(df['text'].iloc[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "490a1f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ex wife threatening suiciderecently i left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>am i weird i don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>finally 2020 is almost over... so i can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>i’m so losthello, my name is adam (16) and i’v...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0           2  ex wife threatening suiciderecently i left my ...      suicide\n",
       "1           3  am i weird i don't get affected by compliments...  non-suicide\n",
       "2           4  finally 2020 is almost over... so i can never ...  non-suicide\n",
       "3           8          i need helpjust help me im crying so hard      suicide\n",
       "4           9  i’m so losthello, my name is adam (16) and i’v...      suicide"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a4610",
   "metadata": {},
   "source": [
    "#### Step 6d: Remove punctuation and numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0a875fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.contains('2').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a81be45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i need helpjust help me im crying so hard\n"
     ]
    }
   ],
   "source": [
    "\n",
    "punctuation = ['-', '-', '⠿','ᒷ','⣵ ⣿','┘','┌','ℸ','⢿ ⣷','⣁','⣵','⣳','⡉ ⡉','¿','↸','⡇', '!', '@', '?', '.', '#', '▀ ▀', '▀', '⢠', '$', '· -·-·-', '⠁' , '%', '^', '&', '€', '*', '(', ')', ':', ';', '<', '>', '\"',  '/', ',', '?', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '[', ']', '{', '}', '|', '⣿ ⢸', '⣶ ⣶', '⣿ ⣶', '⡉ ⡉', '⣿', '⠄', '⣦', '⣷', '⢉', '⠙', '⠟', '▓', '⠉', '⠋', '⠛', '⡟', 'ㅤ ㅤ', '·', '⣧']\n",
    "\n",
    "for item in punctuation:\n",
    "    df['text'] = df['text'].str.replace(item, '')\n",
    "    \n",
    "print(df['text'].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e3eacf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.contains('2').any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856fc1d",
   "metadata": {},
   "source": [
    "#### Step 6e: Remove White Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "051b4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf975be",
   "metadata": {},
   "source": [
    "#### Step 6f: Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "499ce225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "for iter in range(len(df)):\n",
    "    if detect(str(df['text'].iloc[1])) != 'en':\n",
    "        df.drop(i, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fdb6822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232074, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae84f12",
   "metadata": {},
   "source": [
    "#### Step 6g:  Expand Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f34de38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "  \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "\n",
    "  # specific\n",
    "  phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "  phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "  phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "  phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "  # general\n",
    "  phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "  phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "  phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "  phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "  phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "  phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "  phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "  phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "  phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "  phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "  phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "  phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "  return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0944c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df['text'].iloc[i] = decontracted(df['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c57229f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Suicide_Detection_Interim_Clean8622.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944015a",
   "metadata": {},
   "source": [
    "#### Step 6h:  Spell Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb81d1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\betha\\anaconda3\\lib\\site-packages (0.17.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\betha\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\betha\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\betha\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\betha\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\betha\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\betha\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd4eb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c7ae4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(text):\n",
    "    return str((TextBlob(text)).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4d40f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex wife threatening suiciderecently i left my wife for good because she has cheated on me twice and lied to me so much that i have decided to refuse to go back to her as of a few days ago she began threatening suicide i have tirelessly spent these paat few days talking her out of it and she keeps hesitating because she wants to believe i will come back i know a lot of people will threaten this in order to get their way but what happens if she really does what do i do and how am i supposed to handle her death on my hands i still love my wife but i cannot deal with getting cheated on again and constantly feeling insecure i am worried today may be the day she does it and i hope so much it does not happen\n",
      "\n",
      "ex wife threatening suiciderecently i left my wife for good because she has created on me twice and lied to me so much that i have decided to refuse to go back to her as of a few days ago she began threatening suicide i have carelessly spent these part few days talking her out of it and she keeps hesitating because she wants to believe i will come back i know a lot of people will threaten this in order to get their way but what happens if she really does what do i do and how am i supposed to handle her death on my hands i still love my wife but i cannot deal with getting created on again and constantly feeling insecure i am worried today may be the day she does it and i hope so much it does not happen\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].iloc[0])\n",
    "print('')\n",
    "print(spell_check(df['text'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606874c2",
   "metadata": {},
   "source": [
    "##### Note\n",
    "The spell check function does not seem perfect for these purposes.  In the above example it changed a word from 'cheated' to 'created' which really changes the meaning of the sentence.  Since I was reluctant to change the meaning of the text, I opted not to run a spell check function on the entire data set.  \n",
    "\n",
    "However, there were a number of issues with the dataset particularly in joining the word i with the word prior to it.  So I have developed a list of these examples and decided to resolve these spelling mistakes.  These may have been original to the postings or may have been joined while scraping the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d640b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = ['anymoremy','myselfmy', 'meit', 'diemy', 'domy', 'myselfso', 'helphi', 'helpmy', 'lifemy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c2750c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_list = ['diei','suicidei', 'tiredi', 'tonighti', 'anymorei', 'thoughtsi', 'myselfi', 'endi', 'betteri', 'alonei', 'helpi', 'alivei',\n",
    "'sooni', 'livingi', 'pleasei', 'suicidali', 'losti', 'pointi', 'hopei', 'tomorrowi', 'advicei', 'stopi', 'goingi', \n",
    "'hopelessi', 'livei', 'deathi', 'paini', 'personi', 'weeki', 'lifei', 'carei', 'donei', 'depressedi', 'lonelyi', 'attempti',\n",
    "'everythingi', 'scaredi', 'worse', 'everyonei', 'optioni', 'readyi', 'longeri', 'plani', 'headi', 'here', 'goi',\n",
    "'emptyi', 'worthlessi', 'dyingi', 'doi', 'failurei', 'worsei', 'herei', 'worldi', 'anyonei', 'thisi', 'goodbyei', 'notei', \n",
    "'backi', 'someonei', 'iti', 'lefti', 'whyi', 'outi', 'myselft', 'upi', 'nighti', 'todayi', 'yearsi', 'toi', 'mindi', 'anymoret', 'happyi',\n",
    "         'depressioni', 'wayi', 'ssri', 'downi', 'overi', 'nowi', 'sorryi', 'enoughi', 'hospitali', 'optionsi', 'pillsi', 'titlei', 'trappedi', \n",
    "         'edgei', 'yourselfi', 'uselessi', 'ranti', 'okayi', 'tryingi', 'caresi', 'existi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f4e0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_i_my(text):\n",
    "    for i in i_list:\n",
    "        text = text.replace(i, i[:-1])\n",
    "        for j in my_list:\n",
    "            text = text.replace(j, j[:-2])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40e4e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df['text'].iloc[i] = remove_i_my(df['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7225c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('worsi', 'worst')\n",
    "df['text'] = df['text'].str.replace('helpso', 'help so')\n",
    "df['text'] = df['text'].str.replace('ther', 'the')\n",
    "df['text'] = df['text'].str.replace('fuck fuck', 'fuck')\n",
    "df['text'] = df['text'].str.replace('gtpoplt gtpoplt', 'gtpoplt')\n",
    "df['text'] = df['text'].str.replace('cheese cheese', 'cheese')\n",
    "df['text'] = df['text'].str.replace('cecil cecil', 'cecil')\n",
    "df['text'] = df['text'].str.replace('sus sus', 'sus')\n",
    "df['text'] = df['text'].str.replace('cum cum', 'cum')\n",
    "df['text'] = df['text'].str.replace('ni ni', 'ni')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39800f64",
   "metadata": {},
   "source": [
    "#### Step: 6i:  Filler Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f68595",
   "metadata": {},
   "source": [
    "For whatever reason there are many iterations of the word 'filler' throughout the data.  See below for an example of scraped postings with this word repeated many times.  Since this word does not provide any insight into the intention of the author, I am going to remove the word from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86a09e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 253 can constant masturbation lead to disinterest in girls asking for a friend \n",
      "filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler\n",
      "iteration 414 what are some good halloween movies filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler filler\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 600):\n",
    "    if 'filler filler' in df['text'].iloc[i]:\n",
    "        print('iteration' , i , df['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ac9bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('filler', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d130ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Suicide_Detection_Normalized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5031d46",
   "metadata": {},
   "source": [
    "#### Step 6j: Stop Words and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78c803b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Suicide_Detection_Normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c6a71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7788c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d47b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    token = word_tokenize(text)\n",
    "    result = []\n",
    "    for item in token:\n",
    "        if item in STOP_WORDS:\n",
    "            pass\n",
    "        else:\n",
    "            result.append(item)\n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57196ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df['word'].iloc[i] = tokenize(df['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "782f6410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ex wife threatening suiciderecently i left my ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[ex, wife, threatening, suiciderecently, left,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>am i weird i do not get affected by compliment...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[weird, affected, compliments, coming, know, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>finally  is almost over so i can never hear  h...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[finally, hear, bad, year, swear, fucking, god...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[need, helpjust, help, im, crying, hard]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>i am so losthello my name is adam  and i have ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[losthello, adam, struggling, years, afraid, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class  \\\n",
       "0           2  ex wife threatening suiciderecently i left my ...      suicide   \n",
       "1           3  am i weird i do not get affected by compliment...  non-suicide   \n",
       "2           4  finally  is almost over so i can never hear  h...  non-suicide   \n",
       "3           8          i need helpjust help me im crying so hard      suicide   \n",
       "4           9  i am so losthello my name is adam  and i have ...      suicide   \n",
       "\n",
       "                                                word  \n",
       "0  [ex, wife, threatening, suiciderecently, left,...  \n",
       "1  [weird, affected, compliments, coming, know, i...  \n",
       "2  [finally, hear, bad, year, swear, fucking, god...  \n",
       "3           [need, helpjust, help, im, crying, hard]  \n",
       "4  [losthello, adam, struggling, years, afraid, p...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b5864",
   "metadata": {},
   "source": [
    "#### Step 6k: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3880c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "for iter in range(len(df)):\n",
    "    result = []\n",
    "    for word in df['word'].iloc[iter]:\n",
    "        result.append(lemmatizer.lemmatize(word))\n",
    "    df['word'].iloc[iter] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccb7b1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struggling\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('struggling'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d708f619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ex wife threatening suiciderecently i left my ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[ex, wife, threatening, suiciderecently, left,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>am i weird i do not get affected by compliment...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[weird, affected, compliment, coming, know, ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>finally  is almost over so i can never hear  h...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[finally, hear, bad, year, swear, fucking, god...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[need, helpjust, help, im, cry, hard]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>i am so losthello my name is adam  and i have ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[losthello, adam, struggling, year, afraid, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class  \\\n",
       "0           2  ex wife threatening suiciderecently i left my ...      suicide   \n",
       "1           3  am i weird i do not get affected by compliment...  non-suicide   \n",
       "2           4  finally  is almost over so i can never hear  h...  non-suicide   \n",
       "3           8          i need helpjust help me im crying so hard      suicide   \n",
       "4           9  i am so losthello my name is adam  and i have ...      suicide   \n",
       "\n",
       "                                                word  \n",
       "0  [ex, wife, threatening, suiciderecently, left,...  \n",
       "1  [weird, affected, compliment, coming, know, ir...  \n",
       "2  [finally, hear, bad, year, swear, fucking, god...  \n",
       "3              [need, helpjust, help, im, cry, hard]  \n",
       "4  [losthello, adam, struggling, year, afraid, pa...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6baa5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c12e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(len(df)):\n",
    "    words = df['word'].iloc[iter]\n",
    "    words = ' '.join(words)\n",
    "    df['clean_text'].iloc[iter] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49340b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one last replace of repeated or misspelled items found in the clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6288647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['clean_text'].str.replace('ther', 'the')\n",
    "df['clean_text'] = df['clean_text'].str.replace('fuck fuck', 'fuck')\n",
    "df['clean_text'] = df['clean_text'].str.replace('sus sus', 'sus')\n",
    "df['clean_text'] = df['clean_text'].str.replace('cheese cheese', 'cheese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92793ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>word</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ex wife threatening suiciderecently i left my ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[ex, wife, threatening, suiciderecently, left,...</td>\n",
       "      <td>ex wife threatening suiciderecently left wife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>am i weird i do not get affected by compliment...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[weird, affected, compliment, coming, know, ir...</td>\n",
       "      <td>weird affected compliment coming know irl feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>finally  is almost over so i can never hear  h...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[finally, hear, bad, year, swear, fucking, god...</td>\n",
       "      <td>finally hear bad year swear fucking god annoying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[need, helpjust, help, im, cry, hard]</td>\n",
       "      <td>need helpjust help im cry hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>i am so losthello my name is adam  and i have ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[losthello, adam, struggling, year, afraid, pa...</td>\n",
       "      <td>losthello adam struggling year afraid past yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>honetly idki dont know what im even dong her i...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[honetly, idki, dont, know, im, dong, feel, li...</td>\n",
       "      <td>honetly idki dont know im dong feel like nowhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>trigger warning excuse for self inflicted burn...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[trigger, warning, excuse, self, inflicted, bu...</td>\n",
       "      <td>trigger warning excuse self inflicted burnsi k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>it ends tonight can not do it anymore \\ni quit</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[end, tonight, anymore, quit]</td>\n",
       "      <td>end tonight anymore quit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>everyone wants to be edgy and it is making me ...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[want, edgy, making, self, conscious, feel, li...</td>\n",
       "      <td>want edgy making self conscious feel like stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class  \\\n",
       "0           2  ex wife threatening suiciderecently i left my ...      suicide   \n",
       "1           3  am i weird i do not get affected by compliment...  non-suicide   \n",
       "2           4  finally  is almost over so i can never hear  h...  non-suicide   \n",
       "3           8          i need helpjust help me im crying so hard      suicide   \n",
       "4           9  i am so losthello my name is adam  and i have ...      suicide   \n",
       "5          11  honetly idki dont know what im even dong her i...      suicide   \n",
       "6          12  trigger warning excuse for self inflicted burn...      suicide   \n",
       "7          13     it ends tonight can not do it anymore \\ni quit      suicide   \n",
       "8          16  everyone wants to be edgy and it is making me ...  non-suicide   \n",
       "\n",
       "                                                word  \\\n",
       "0  [ex, wife, threatening, suiciderecently, left,...   \n",
       "1  [weird, affected, compliment, coming, know, ir...   \n",
       "2  [finally, hear, bad, year, swear, fucking, god...   \n",
       "3              [need, helpjust, help, im, cry, hard]   \n",
       "4  [losthello, adam, struggling, year, afraid, pa...   \n",
       "5  [honetly, idki, dont, know, im, dong, feel, li...   \n",
       "6  [trigger, warning, excuse, self, inflicted, bu...   \n",
       "7                      [end, tonight, anymore, quit]   \n",
       "8  [want, edgy, making, self, conscious, feel, li...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  ex wife threatening suiciderecently left wife ...  \n",
       "1  weird affected compliment coming know irl feel...  \n",
       "2   finally hear bad year swear fucking god annoying  \n",
       "3                     need helpjust help im cry hard  \n",
       "4  losthello adam struggling year afraid past yea...  \n",
       "5  honetly idki dont know im dong feel like nowhe...  \n",
       "6  trigger warning excuse self inflicted burnsi k...  \n",
       "7                           end tonight anymore quit  \n",
       "8  want edgy making self conscious feel like stan...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f498ec7",
   "metadata": {},
   "source": [
    "# Step 7:  Save Cleaned File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12fc6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Suicide_Detection_DataWrangling.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
