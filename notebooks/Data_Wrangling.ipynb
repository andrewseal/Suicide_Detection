{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c1111f",
   "metadata": {},
   "source": [
    "# Suicide Detection - Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae227886",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [Step 1. Imports](#Step-1:--Imports) \n",
    "* [Step 2. Load the Data](#Step-2:--Load-the-Data)\n",
    "* [Step 3.  Review Summary Data](#Step-3:--Look-at-Summary-of-Data)\n",
    "* [Step 4.  Further Data Review (Head)](#Step-4:--Call-head-of-Data)\n",
    "* [Step 5.  Identify Duplicates and Missing Data](#Step-5:--Identify-duplicates-and-missing-data)\n",
    "* [Step 6.  Text Normalization](#Step-6:--Text-Normalization)\n",
    "    * [Step 6a)  Convert Text to Lowercase](#Step-6a:--Convert-all-letters-to-lowercase.)\n",
    "    * [Step 6b)  Convert urls and links to standardized text](#Step-6b:--Convert-urls-and-links-to-standardized-text)\n",
    "    * [Step 6c)  Convert emojis and emoticons to text](#Step-6c:-Convert-emojis-and-emoticons-to-text)\n",
    "    * [Step 6d)  Remove punctuation and numerals](#Step-6d:-Remove-punctuation-and-numerals)\n",
    "    * [Step 6e)  Remove White Spaces](#Step-6e:-Remove-White-Spaces)\n",
    "    * [Step 6f)  Language Detection](#Step-6f:-Language-Detection)\n",
    "    * [Step 6g)  Convert Text to Lowercase](#Step-6g:--Expand-Contractions)\n",
    "    * [Step 6h)  Spell Check](#Step-6h:--Spell-Check)\n",
    "    * [Step 6i)  Stop Words and Tokenization](#Step-6i:-Stop-Words-and-Tokenization)\n",
    "    * [Step 6j)  Lemmatization](#Step-6j:-Lemmatization)\n",
    "* [Step 7.  Save Cleaned File](#Step-7:--Save-Cleaned-File)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901d8cc",
   "metadata": {},
   "source": [
    "# Step 1:  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c298676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from six.moves import range\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "import textstat\n",
    "import re\n",
    "import string\n",
    "# !pip install watermark\n",
    "#%load_ext watermark\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124feb1",
   "metadata": {},
   "source": [
    "# Step 2:  Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc4a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Suicide_Detection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b748d03",
   "metadata": {},
   "source": [
    "# Step 3:  Look at Summary of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7100dfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232074 entries, 0 to 232073\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  232074 non-null  int64 \n",
      " 1   text        232074 non-null  object\n",
      " 2   class       232074 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977786f",
   "metadata": {},
   "source": [
    "# Step 4:  Call head of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099b0676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>I’m so lostHello, my name is Adam (16) and I’v...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0           2  Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
       "1           3  Am I weird I don't get affected by compliments...  non-suicide\n",
       "2           4  Finally 2020 is almost over... So I can never ...  non-suicide\n",
       "3           8          i need helpjust help me im crying so hard      suicide\n",
       "4           9  I’m so lostHello, my name is Adam (16) and I’v...      suicide"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655a2f9",
   "metadata": {},
   "source": [
    "# Step 5:  Identify duplicates and missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a2f97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232074"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab24146",
   "metadata": {},
   "source": [
    "This basically tells us that each entry  in the 'text' column is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8a54c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    232074\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c2a647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    232074\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99e282",
   "metadata": {},
   "source": [
    "Great we do not appear to have any duplicates or missing data.  In this regard the data is very clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998e142",
   "metadata": {},
   "source": [
    "# Step 6:  Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2253493",
   "metadata": {},
   "source": [
    "#### Step 6a:  Convert all letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b0a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb68b4d",
   "metadata": {},
   "source": [
    "#### Step 6b:  Convert urls and links to standardized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22844fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  used code snippets from - https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['text'].iloc[i] = no_link_string = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '_link_to_site_', df['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b602baf2",
   "metadata": {},
   "source": [
    "#### Step 6c: Convert emojis and emoticons to text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed02e7f",
   "metadata": {},
   "source": [
    "First we will convert emojis to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b951736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32247267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I won :1st_place_medal: in :cricket_game:\n",
      "Python is the :bomb:\n"
     ]
    }
   ],
   "source": [
    "text1 = \"I won 🥇 in 🏏\"\n",
    "text2 = 'Python is the 💣'\n",
    "\n",
    "print(emoji.demojize(text1))\n",
    "print(emoji.demojize(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ffcbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "for i in range(len(df)):\n",
    "    df['text'].iloc[i] = emoji.demojize(df['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd71546",
   "metadata": {},
   "source": [
    "Next we will convert emoticons to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6243f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emot.emo_unicode import UNICODE_EMOJI # For emojis\n",
    "from emot.emo_unicode import EMOTICONS_EMO# For EMOTICONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f532ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS_EMO:\n",
    "        text = text.replace(emot, EMOTICONS_EMO[emot].replace(\" \",\"_\"))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b328fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Happy_face_smiley Happy_face_smiley'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello :-) :-)\"\n",
    "convert_emoticons(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66d5e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(len(df)):\n",
    "    df['text'].iloc[iter] = convert_emoticons(df['text'].iloc[iter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "490a1f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ex wife threatening suiciderecently i left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>am i weird i don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>finally 2020 is almost over... so i can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>i’m so losthello, my name is adam (16) and i’v...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0           2  ex wife threatening suiciderecently i left my ...      suicide\n",
       "1           3  am i weird i don't get affected by compliments...  non-suicide\n",
       "2           4  finally 2020 is almost over... so i can never ...  non-suicide\n",
       "3           8          i need helpjust help me im crying so hard      suicide\n",
       "4           9  i’m so losthello, my name is adam (16) and i’v...      suicide"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a4610",
   "metadata": {},
   "source": [
    "#### Step 6d: Remove punctuation and numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0a875fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.contains('2').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a81be45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i need helpjust help me im crying so hard\n"
     ]
    }
   ],
   "source": [
    "\n",
    "punctuation = ['!', '@', '?', '.', '#', '$', '%', '^', '&', '€', '*', '(', ')', ':', ';', '<', '>', '\"',  '/', ',', '?', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '[', ']', '{', '}', '|']\n",
    "\n",
    "for item in punctuation:\n",
    "    df['text'] = df['text'].str.replace(item, '')\n",
    "    \n",
    "print(df['text'].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e3eacf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.contains('2').any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856fc1d",
   "metadata": {},
   "source": [
    "#### Step 6e: Remove White Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "051b4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf975be",
   "metadata": {},
   "source": [
    "#### Step 6f: Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "499ce225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "for iter in range(len(df)):\n",
    "    if detect(str(df['text'].iloc[1])) != 'en':\n",
    "        df.drop(i, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fdb6822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232074, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae84f12",
   "metadata": {},
   "source": [
    "#### Step 6g:  Expand Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f34de38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "  \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "\n",
    "  # specific\n",
    "  phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "  phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "  phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "  phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "  # general\n",
    "  phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "  phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "  phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "  phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "  phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "  phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "  phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "  phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "  phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "  phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "  phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "  phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "  return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0944c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(df)):\n",
    "    df['text'].iloc[i] = decontracted(df['text'].iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c57229f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Suicide_Detection_Interim_Clean8622.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944015a",
   "metadata": {},
   "source": [
    "#### Step 6h:  Spell Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd4eb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a148c2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ex wife threatening suiciderecently i left my wife for good because she has cheated on me twice and lied to me so much that i have decided to refuse to go back to her as of a few days ago she began threatening suicide i have tirelessly spent these paat few days talking her out of it and she keeps hesitating because she wants to believe i will come back i know a lot of people will threaten this in order to get their way but what happens if she really does what do i do and how am i supposed to handle her death on my hands i still love my wife but i cannot deal with getting cheated on again and constantly feeling insecure i am worried today may be the day she does it and i hope so much it does not happen'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc88d3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ex wife threatening suiciderecently i left my wife for good because she has created on me twice and lied to me so much that i have decided to refuse to go back to her as of a few days ago she began threatening suicide i have carelessly spent these part few days talking her out of it and she keeps hesitating because she wants to believe i will come back i know a lot of people will threaten this in order to get their way but what happens if she really does what do i do and how am i supposed to handle her death on my hands i still love my wife but i cannot deal with getting created on again and constantly feeling insecure i am worried today may be the day she does it and i hope so much it does not happen'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(TextBlob(df['text'].iloc[0]).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da9c6bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Beth &\n",
      "[nltk_data]     Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing the nltk suite \n",
    "import nltk\n",
    "  \n",
    "# importing edit distance  \n",
    "from nltk.metrics.distance  import edit_distance\n",
    "\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f45bc865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "therapy\n",
      "elephant\n",
      "aiming\n",
      "intelligent\n"
     ]
    }
   ],
   "source": [
    "correct_words = words.words()\n",
    "\n",
    "incorrect_words=['thehappy', 'elephant', 'azmaing', 'intelliengt']\n",
    "\n",
    "for word in incorrect_words:\n",
    "    temp = [(edit_distance(word, w),w) for w in correct_words if w[0]==word[0]]\n",
    "    print(sorted(temp, key = lambda val:val[0])[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7f253",
   "metadata": {},
   "source": [
    "Note:  In this notebook I attempted two different methods for spell checking our dataset.  Neither method was perfect and while some improvements were made, it was observed that many of the changes made my the spell checker actually changed the meaning of the text.  It was decided that it would be better to leave any spelling errors than it would be to alter the meaning of the original text.  Therefore spell checker was NOT applied to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c888e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Suicide_Detection_Normalized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5031d46",
   "metadata": {},
   "source": [
    "#### Step 6i: Stop Words and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78c803b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Suicide_Detection_Normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c6a71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7788c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "107f782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for iter in range(len(df)):\n",
    "    \n",
    "    token = word_tokenize(df['text'].iloc[iter])\n",
    "    result = []\n",
    "    for item in token:\n",
    "        if item in STOP_WORDS:\n",
    "            pass\n",
    "        else:\n",
    "            result.append(item)\n",
    "        \n",
    "    df['word'].iloc[iter] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "782f6410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ex wife threatening suiciderecently i left my ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[ex, wife, threatening, suiciderecently, left,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>am i weird i do not get affected by compliment...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[weird, affected, compliments, coming, know, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>finally  is almost over so i can never hear  h...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[finally, hear, bad, year, swear, fucking, god...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[need, helpjust, help, im, crying, hard]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>i am so losthello my name is adam  and i have ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[losthello, adam, struggling, years, afraid, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class  \\\n",
       "0           2  ex wife threatening suiciderecently i left my ...      suicide   \n",
       "1           3  am i weird i do not get affected by compliment...  non-suicide   \n",
       "2           4  finally  is almost over so i can never hear  h...  non-suicide   \n",
       "3           8          i need helpjust help me im crying so hard      suicide   \n",
       "4           9  i am so losthello my name is adam  and i have ...      suicide   \n",
       "\n",
       "                                                word  \n",
       "0  [ex, wife, threatening, suiciderecently, left,...  \n",
       "1  [weird, affected, compliments, coming, know, i...  \n",
       "2  [finally, hear, bad, year, swear, fucking, god...  \n",
       "3           [need, helpjust, help, im, crying, hard]  \n",
       "4  [losthello, adam, struggling, years, afraid, p...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b5864",
   "metadata": {},
   "source": [
    "#### Step 6j: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3880c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "for iter in range(len(df)):\n",
    "    result = []\n",
    "    for word in df['word'].iloc[iter]:\n",
    "        result.append(lemmatizer.lemmatize(word))\n",
    "    df['word'].iloc[iter] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d708f619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ex wife threatening suiciderecently i left my ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[ex, wife, threatening, suiciderecently, left,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>am i weird i do not get affected by compliment...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[weird, affected, compliment, coming, know, ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>finally  is almost over so i can never hear  h...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[finally, hear, bad, year, swear, fucking, god...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[need, helpjust, help, im, cry, hard]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>i am so losthello my name is adam  and i have ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[losthello, adam, struggling, year, afraid, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class  \\\n",
       "0           2  ex wife threatening suiciderecently i left my ...      suicide   \n",
       "1           3  am i weird i do not get affected by compliment...  non-suicide   \n",
       "2           4  finally  is almost over so i can never hear  h...  non-suicide   \n",
       "3           8          i need helpjust help me im crying so hard      suicide   \n",
       "4           9  i am so losthello my name is adam  and i have ...      suicide   \n",
       "\n",
       "                                                word  \n",
       "0  [ex, wife, threatening, suiciderecently, left,...  \n",
       "1  [weird, affected, compliment, coming, know, ir...  \n",
       "2  [finally, hear, bad, year, swear, fucking, god...  \n",
       "3              [need, helpjust, help, im, cry, hard]  \n",
       "4  [losthello, adam, struggling, year, afraid, pa...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6baa5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c12e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(len(df)):\n",
    "    words = df['word'].iloc[iter]\n",
    "    words = ' '.join(words)\n",
    "    df['clean_text'].iloc[iter] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92793ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>word</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ex wife threatening suiciderecently i left my ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[ex, wife, threatening, suiciderecently, left,...</td>\n",
       "      <td>ex wife threatening suiciderecently left wife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>am i weird i do not get affected by compliment...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[weird, affected, compliment, coming, know, ir...</td>\n",
       "      <td>weird affected compliment coming know irl feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>finally  is almost over so i can never hear  h...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[finally, hear, bad, year, swear, fucking, god...</td>\n",
       "      <td>finally hear bad year swear fucking god annoying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[need, helpjust, help, im, cry, hard]</td>\n",
       "      <td>need helpjust help im cry hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>i am so losthello my name is adam  and i have ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[losthello, adam, struggling, year, afraid, pa...</td>\n",
       "      <td>losthello adam struggling year afraid past yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>honetly idki dont know what im even doing here...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[honetly, idki, dont, know, im, feel, like, fe...</td>\n",
       "      <td>honetly idki dont know im feel like feel unbea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>trigger warning excuse for self inflicted burn...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[trigger, warning, excuse, self, inflicted, bu...</td>\n",
       "      <td>trigger warning excuse self inflicted burnsi k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>it ends tonighti can not do it anymore \\ni quit</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[end, tonighti, anymore, quit]</td>\n",
       "      <td>end tonighti anymore quit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>everyone wants to be edgy and it is making me ...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[want, edgy, making, self, conscious, feel, li...</td>\n",
       "      <td>want edgy making self conscious feel like stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class  \\\n",
       "0           2  ex wife threatening suiciderecently i left my ...      suicide   \n",
       "1           3  am i weird i do not get affected by compliment...  non-suicide   \n",
       "2           4  finally  is almost over so i can never hear  h...  non-suicide   \n",
       "3           8          i need helpjust help me im crying so hard      suicide   \n",
       "4           9  i am so losthello my name is adam  and i have ...      suicide   \n",
       "5          11  honetly idki dont know what im even doing here...      suicide   \n",
       "6          12  trigger warning excuse for self inflicted burn...      suicide   \n",
       "7          13    it ends tonighti can not do it anymore \\ni quit      suicide   \n",
       "8          16  everyone wants to be edgy and it is making me ...  non-suicide   \n",
       "\n",
       "                                                word  \\\n",
       "0  [ex, wife, threatening, suiciderecently, left,...   \n",
       "1  [weird, affected, compliment, coming, know, ir...   \n",
       "2  [finally, hear, bad, year, swear, fucking, god...   \n",
       "3              [need, helpjust, help, im, cry, hard]   \n",
       "4  [losthello, adam, struggling, year, afraid, pa...   \n",
       "5  [honetly, idki, dont, know, im, feel, like, fe...   \n",
       "6  [trigger, warning, excuse, self, inflicted, bu...   \n",
       "7                     [end, tonighti, anymore, quit]   \n",
       "8  [want, edgy, making, self, conscious, feel, li...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  ex wife threatening suiciderecently left wife ...  \n",
       "1  weird affected compliment coming know irl feel...  \n",
       "2   finally hear bad year swear fucking god annoying  \n",
       "3                     need helpjust help im cry hard  \n",
       "4  losthello adam struggling year afraid past yea...  \n",
       "5  honetly idki dont know im feel like feel unbea...  \n",
       "6  trigger warning excuse self inflicted burnsi k...  \n",
       "7                          end tonighti anymore quit  \n",
       "8  want edgy making self conscious feel like stan...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f498ec7",
   "metadata": {},
   "source": [
    "# Step 7:  Save Cleaned File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12fc6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Suicide_Detection_DataWrangling.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
